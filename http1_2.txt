HTTP.1:
The Hypertext Transfer Protocol, or HTTP, is an application protocol that has been the de facto standard
 for communication on the World Wide Web since its invention in 1989. 

Developed by Timothy Berners-Lee in 1989 as a communication standard for the World Wide Web,
HTTP is a top-level application protocol that exchanges information between a client computer and a local or remote web server.
In this process, a client sends a text-based request to a server by calling a method like GET or POST.
In response, the server sends a resource like an HTML page back to the client.

For example, let’s say you are visiting a website at the domain www.example.com.
When you navigate to this URL, the web browser on your computer sends an HTTP request in the form of a text-based message,
similar to the one shown here:

GET /index.html HTTP/1.1
Host: www.example.com

This request uses the GET method, which asks for data from the host server listed after Host:.
In response to this request, the example.com web server returns an HTML page to the requesting client, 
in addition to any images, stylesheets, or other resources called for in the HTML. 
Note that not all of the resources are returned to the client in the first call for data.
The requests and responses will go back and forth between the server and client until the web browser has received all the resources
necessary to render the contents of the HTML page on your screen.

In HTTP/1.1, flow control relies on the underlying TCP connection. When this connection initiates,
both client and server establish their buffer sizes using their system default settings.
If the receiver’s buffer is partially filled with data, it will tell the sender its receive window, 
i.e., the amount of available space that remains in its buffer. This receive window is advertised in a signal known as an ACK packet,
which is the data packet that the receiver sends to acknowledge that it received the opening signal. 
If this advertised receive window size is zero, the sender will send no more data until the client clears its internal buffer
and then requests to resume data transmission. It is important to note here that using receive windows based on the underlying TCP connection can only implement flow control on either end of the connection.

Because HTTP/1.1 relies on the transport layer to avoid buffer overflow, each new TCP connection requires a separate flow control mechanism.
 HTTP/2, however, multiplexes streams within a single TCP connection, and will have to implement flow control in a different manner.

HTTP.2:

 In 2015, a reimagined version called HTTP/2 came into use, which offered several methods to decrease latency,
 especially when dealing with mobile platforms and server-intensive graphics and videos. HTTP/2 has since become increasingly popular
 with some estimates suggesting that around a third of all websites in the world support it.

HTTP/2 began as the SPDY protocol, developed primarily at Google with the intention of 
reducing web page load latency by using techniques such as compression, multiplexing, and prioritization.
This protocol served as a template for HTTP/2 when the Hypertext Transfer Protocol working group httpbis of the IETF (Internet Engineering Task Force) put the standard together, culminating in the publication of HTTP/2 in May 2015.

 From the beginning, many browsers supported this standardization effort, including Chrome, Opera, Internet Explorer,and Safari. Due in part to this browser support, there has been a significant adoption rate of the protocol since 2015, with especially high rates among new sites.
 
 From a technical point of view, one of the most significant features that distinguishes HTTP/1.1 and HTTP/2 is the binary framing layer, which can be thought of as a part of the application layer in the internet protocol stack. As opposed to HTTP/1.1, which keeps all requests and responses in plain text format, HTTP/2 uses the binary framing layer to encapsulate all messages in binary format, while still maintaining HTTP semantics, such as verbs, methods, and headers. An application level API would still create messages in the conventional HTTP formats, but the underlying layer would then convert these messages into binary. This ensures that web applications created before HTTP/2 can continue functioning as normal when interacting with the new protocol.

The conversion of messages into binary allows HTTP/2 to try new approaches to data delivery not available in HTTP/1.1, a contrast that is at the root of the practical differences between the two protocols. The next section will take a look at the delivery model of HTTP/1.1, followed by what new models are made possible by HTTP/2.

HTTP/2 multiplexes streams of data within a single TCP connection. As a result, receive windows on the level of the TCP connection are not sufficient to regulate the delivery of individual streams. HTTP/2 solves this problem by allowing the client and server to implement their own flow controls, rather than relying on the transport layer. The application layer communicates the available buffer space, allowing the client and server to set the receive window on the level of the multiplexed streams. This fine-scale flow control can be modified or maintained after the initial connection via a WINDOW_UPDATE frame.

Since this method controls data flow on the level of the application layer, the flow control mechanism does not have to wait for a signal to reach its ultimate destination before adjusting the receive window. Intermediary nodes can use the flow control settings information to determine their own resource allocations and modify accordingly. In this way, each intermediary server can implement its own custom resource strategy, allowing for greater connection efficiency.

This flexibility in flow control can be advantageous when creating appropriate resource strategies. For example, the client may fetch the first scan of an image, display it to the user, and allow the user to preview it while fetching more critical resources. Once the client fetches these critical resources, the browser will resume the retrieval of the remaining part of the image. Deferring the implementation of flow control to the client and server can thus improve the perceived performance of web applications.

In terms of flow control and the stream prioritization mentioned in an earlier section, HTTP/2 provides a more detailed level of control that opens up the possibility of greater optimization. The next section will explain another method unique to the protocol that can enhance a connection in a similar way: predicting resource requests with server push.
